PIPELINE_VERSION: 4.4.0-Origin
--- INFRASTRUCTURE ---
{
    "os": "Linux",
    "python": "3.12.12",
    "device": "Tesla T4",
    "vram_total": "15.83 GB"
}
[TIMER] Phase 'data_infrastructure' completed in 1.59s
[TIMER] Phase 'data_cleaning' completed in 0.12s
--- TOKENIZER ---
{
    "vocab_size": 20000,
    "status": "REUSED",
    "duration": "0.00s"
}
Epoch 01 | Loss: 7.8806 | Val: 7.5221 | LR: 0.000198 | Time: 263.15s
Epoch 02 | Loss: 6.9587 | Val: 7.5257 | LR: 0.000468 | Time: 261.03s
Epoch 03 | Loss: 6.8510 | Val: 7.5048 | LR: 0.000486 | Time: 260.97s
Epoch 04 | Loss: 6.7946 | Val: 7.4761 | LR: 0.000406 | Time: 263.23s
Epoch 05 | Loss: 6.6334 | Val: 7.4499 | LR: 0.000278 | Time: 262.42s
Epoch 06 | Loss: 6.4956 | Val: 7.4333 | LR: 0.000141 | Time: 264.95s
Epoch 07 | Loss: 6.3759 | Val: 7.4457 | LR: 0.000038 | Time: 260.42s
Epoch 08 | Loss: 6.3230 | Val: 7.4505 | LR: 0.000000 | Time: 265.88s
[TIMER] Phase 'model_training' completed in 2299.81s
[TIMER] Phase 'evaluation_fast' completed in 9.17s

--- FINAL EVALUATION (FAST) ---
{
    "file": "20260204_1008_lstm_bahdanau_sub20000.pt",
    "model": "lstm_bahdanau",
    "bleu": 0.0006497674895921603,
    "rougeL": 0.13414574392997358,
    "eval_mode": "fast"
}

--- ALL PHASE DURATIONS ---
{
    "data_infrastructure": "1.59s",
    "data_cleaning": "0.12s",
    "model_training": "2299.81s",
    "evaluation_fast": "9.17s",
    "total_execution": "0:38:50.431186"
}

--- FINISHED ---
Total Duration: 0:38:50.431186
