================================================================================
Code Snapshot for Project: Project
Generated on: 2026-01-19 18:12:47
================================================================================

--- FILE: configs.txt | PATH: Project\configs.txt ---
-----------------------------------------------------

# Specifiche Tecniche: ML-Based Python Code Summarization

metadata:
  data: 12 Gennaio 2026
  deadline: 
    code_report: 16 Gennaio 2026
    discussione: 23 Gennaio 2026
  corso: Machine Learning for Software Analysis

obiettivo_core:
  descrizione: Sviluppare un tool basato su PyTorch che esegua la "code summarization".
  input: Codice sorgente Python (es. funzioni, metodi).
  output: Descrizione testuale (docstring/summary).

vincoli_tecnici:
  non_permesso:
    - Utilizzo di Full Language Models pre-addestrati (es. BERT, GPT-2, CodeBERT, T5 caricati con pesi pre-esistenti).
    - Utilizzo di modelli già addestrati specificamente su sintassi o semantica Python.
    - Il modello core deve essere addestrato da zero (from scratch) sui dati scelti.
  permesso:
    - Utilizzo di Tokenizer pre-addestrati (es. Byte-Pair Encoding, WordPiece).
    - Utilizzo di Matrici di Embedding pre-addestrate (es. GloVe, Word2Vec), purché non siano parte di un modello Transformer intero.
    - Utilizzo di LLM (ChatGPT, Claude) per assistenza alla scrittura del codice o debugging (da documentare esplicitamente nel report).
    - Adattamento di codice open-source (con attribuzione).

architettura_richiesta:
  framework: PyTorch
  tipologia: Sequence-to-Sequence (Encoder-Decoder) o Transformer-based (Custom).
  componenti:
    - preprocessing: Tokenizzazione codice sorgente e riassunti.
    - encoder: Processa la sequenza di codice.
    - decoder: Genera la sequenza di testo (riassunto).
    - training_loop: Implementazione standard (Forward pass, Loss calculation, Backward pass, Optimizer step).

dati:
  fonte: Dataset pubblici contenenti coppie (codice python, docstring/riassunto).
  suggerimento: CodeSearchNet (o subset filtrati da GitHub/StackOverflow).
  requisito: Il dataset deve essere sufficientemente ampio per permettere la convergenza del training, ma gestibile entro i tempi di calcolo disponibili.

deliverables:
  codebase:
    linguaggio: Python/PyTorch
    struttura_raccomandata:
      - src/: Codice sorgente.
      - data/: Script per il download/processing dati.
      - models/: Definizioni delle classi PyTorch (Encoder, Decoder, Seq2Seq).
      - scripts/: Script eseguibili.
    scripts_funzionali:
      - training: python train.py
      - evaluation: python evaluate.py
      - inference: python summarize.py --input "def func(): ..."
  report:
    formato: PDF, 5-6 Pagine
    sezioni:
      - Introduzione e Obiettivi.
      - Metodologia: Descrizione dataset, preprocessing, architettura modello (giustificazione scelte).
      - Risultati: Grafici loss (train/val), tabelle metriche.
      - Discussione: Analisi errori, limitazioni.
      - Appendice: Contributi membri gruppo, Riferimenti (incluso uso LLM).
  readme:
    contenuto: Istruzioni chiare per installare dipendenze, preparare dati e avviare training, valutazione, inferenza.

metriche_valutazione:
  - Cross-Entropy Loss (Durante il training/validation).
  - BLEU Score (Metrica standard per traduzione automatica/generazione testo).
  - ROUGE Score (Metrica per la qualità del riassunto).
  - Perplexity (Opzionale ma raccomandata per modelli linguistici).

roadmap_operativa:
  - Day 1 (Oggi): Setup ambiente, scelta dataset (es. CodeSearchNet slice), pipeline di preprocessing funzionante (Text -> Tokens -> IDs).
  - Day 2: Implementazione modello Seq2Seq semplice (LSTM o Transformer base). Primo run di training "dummy" per verificare che non crashi.
  - Day 3: Training serio (overnight se necessario). Implementazione script di valutazione (BLEU/ROUGE).
  - Day 4: Scrittura Report, cleanup codice, creazione README.


================================================================================

--- FILE: requirements.txt | PATH: Project\requirements.txt ---
---------------------------------------------------------------

# requirements.txt generated by script on 2026-01-12
# This is a best-effort list based on static analysis.
# Package names may differ from import names (e.g., 'sklearn' -> 'scikit-learn').
# Please review and update as necessary.

# No third-party packages detected.


================================================================================

--- FILE: README.md | PATH: Project\data\README.md ---
------------------------------------------------------

# Cartella `data`

Questa cartella conterrà tutti gli script e i file relativi alla gestione del dataset.

## Implementazione Prevista

1.  **Script di Acquisizione (`download_dataset.py`):**
    *   Uno script per scaricare e scompattare il dataset (es. CodeSearchNet) nella cartella `Project/Datasets`.
    *   Dovrebbe permettere di scaricare anche solo un subset per testare rapidamente la pipeline.

2.  **Script di Preprocessing (`preprocess.py`):**
    *   **Tokenizzazione:** Questo script si occuperà di convertire sia il codice sorgente che i riassunti testuali in sequenze di token. Verranno usati tokenizer specifici (es. BPE) per ogni "linguaggio" (codice e testo).
    *   **Costruzione Vocabolario:** Creerà e salverà i vocabolari (mappe `token -> id`) per il codice e per i riassunti, includendo token speciali come `<PAD>`, `<SOS>`, `<EOS>`, `<UNK>`.

3.  **Classe `Dataset` PyTorch (`dataset.py`):**
    *   Implementerà una classe `torch.utils.data.Dataset` custom.
    *   Questa classe leggerà i dati pre-processati, li convertirà in tensori numerici e li servirà al `DataLoader`.

4.  **Funzione di Utilità per `DataLoader`:**
    *   Una funzione helper che, data una classe `Dataset`, istanzi e restituisca i `DataLoader` per training, validazione e test.
    *   Gestirà la logica per il padding dei batch (tramite l'argomento `collate_fn`) in modo che tutte le sequenze in un batch abbiano la stessa lunghezza.


================================================================================

--- FILE: attention.py | PATH: Project\models\attention.py ---
--------------------------------------------------------------

import torch
import torch.nn as nn
import torch.nn.functional as F

class Attention(nn.Module):
    def __init__(self, hid_dim):
        super().__init__()
        self.attn = nn.Linear(hid_dim * 2, hid_dim)
        self.v = nn.Linear(hid_dim, 1, bias=False)
        
    def forward(self, hidden, encoder_outputs):
        # hidden: [batch_size, hid_dim] -> ultimo stato del decoder
        # encoder_outputs: [batch_size, src_len, hid_dim]
        
        batch_size = encoder_outputs.shape[0]
        src_len = encoder_outputs.shape[1]
        
        # Ripeti lo stato nascosto per ogni step dell'encoder
        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)
        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))
        attention = self.v(energy).squeeze(2)
        # attention: [batch_size, src_len]
        
        return F.softmax(attention, dim=1)

================================================================================

--- FILE: decoder.py | PATH: Project\models\decoder.py ---
----------------------------------------------------------

import torch
import torch.nn as nn

class Decoder(nn.Module):
    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout, attention):
        super().__init__()
        self.output_dim = output_dim
        self.attention = attention
        self.embedding = nn.Embedding(output_dim, emb_dim)
        # LSTM riceve (embedding + context_vector)
        self.rnn = nn.LSTM(emb_dim + hid_dim, hid_dim, n_layers, dropout=dropout, batch_first=True)
        self.fc_out = nn.Linear(emb_dim + hid_dim * 2, output_dim)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, input, hidden, cell, encoder_outputs):
        # input: [batch_size] -> token precedente
        input = input.unsqueeze(1)
        embedded = self.dropout(self.embedding(input)) # [batch_size, 1, emb_dim]
        
        # Calcolo Attention tra l'ultimo hidden state e tutti gli encoder_outputs
        a = self.attention(hidden[-1], encoder_outputs) # [batch_size, src_len]
        a = a.unsqueeze(1) # [batch_size, 1, src_len]
        
        # Context vector: somma pesata degli encoder outputs
        weighted = torch.bmm(a, encoder_outputs) # [batch_size, 1, hid_dim]
        
        # Concatenazione embedding + context per la RNN
        rnn_input = torch.cat((embedded, weighted), dim=2)
        output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))
        
        # Predizione finale concatenando tutto per massimizzare il segnale
        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=2))
        
        return prediction.squeeze(1), hidden, cell

================================================================================

--- FILE: encoder.py | PATH: Project\models\encoder.py ---
----------------------------------------------------------

import torch
import torch.nn as nn

class Encoder(nn.Module):
    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):
        super().__init__()
        self.embedding = nn.Embedding(input_dim, emb_dim)
        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, src):
        # src: [batch_size, src_len]
        embedded = self.dropout(self.embedding(src))
        outputs, (hidden, cell) = self.rnn(embedded)
        # outputs: [batch_size, src_len, hid_dim]
        # hidden/cell: [n_layers, batch_size, hid_dim]
        return outputs, hidden, cell

================================================================================

--- FILE: seq2seq.py | PATH: Project\models\seq2seq.py ---
----------------------------------------------------------

import torch
import torch.nn as nn
import random

class Seq2Seq(nn.Module):
    def __init__(self, encoder, decoder, device):
        super().__init__()
        self.encoder = encoder
        self.decoder = decoder
        self.device = device
        
    def forward(self, src, trg, teacher_forcing_ratio=0.5):
        # src: [batch_size, src_len], trg: [batch_size, trg_len]
        batch_size = src.shape[0]
        trg_len = trg.shape[1]
        trg_vocab_size = self.decoder.output_dim
        
        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)
        encoder_outputs, hidden, cell = self.encoder(src)
        
        # Primo input: token <SOS>
        input = trg[:, 0]
        
        for t in range(1, trg_len):
            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)
            outputs[:, t] = output
            
            # Decidi se usare la verità o la previsione
            teacher_force = random.random() < teacher_forcing_ratio
            top1 = output.argmax(1)
            input = trg[:, t] if teacher_force else top1
            
        return outputs

================================================================================

--- FILE: README.md | PATH: Project\scripts\README.md ---
---------------------------------------------------------

# Cartella `scripts`

Questa cartella conterrà gli script eseguibili per lanciare le operazioni principali del progetto: addestramento, valutazione e inferenza.

## Implementazione Prevista

1.  **Script di Addestramento (`train.py`):**
    *   **Responsabilità:** Gestire l'intero ciclo di vita dell'addestramento del modello.
    *   **Logica:**
        1.  Caricare i dati di training e validazione usando i `DataLoader` definiti in `data/`.
        2.  Inizializzare il modello (es. `Seq2Seq`), l'ottimizzatore (es. `Adam`) e la funzione di loss (`NLLLoss` o `CrossEntropyLoss` con `ignore_index` per il padding).
        3.  Eseguire il ciclo di training per un numero definito di `epoch`.
        4.  Per ogni `epoch`:
            *   Iterare sui batch di training, calcolare la loss, eseguire backpropagation e aggiornare i pesi.
            *   Eseguire un ciclo di validazione per monitorare le performance su dati non visti.
            *   Salvare i "checkpoint" del modello, specialmente quello con la migliore performance sul validation set.
        5.  (Opzionale) Loggare le metriche (es. loss, perplessità) usando `TensorBoard` o tool simili.

2.  **Script di Valutazione (`evaluate.py`):**
    *   **Responsabilità:** Valutare quantitativamente un modello addestrato sul test set.
    *   **Logica:**
        1.  Caricare il `DataLoader` del test set.
        2.  Caricare il modello migliore salvato dallo script di training.
        3.  Iterare sul test set in modalità `torch.no_grad()`.
        4.  Per ogni coppia (codice, riassunto reale), generare un riassunto predetto dal modello.
        5.  Calcolare e riportare le metriche di valutazione richieste: **BLEU** e **ROUGE**.

3.  **Script di Inferenza (`summarize.py`):**
    *   **Responsabilità:** Usare il modello addestrato per generare un riassunto di un nuovo snippet di codice fornito dall'utente.
    *   **Logica:**
        1.  Accettare uno snippet di codice come argomento da linea di comando.
        2.  Caricare il modello addestrato, i vocabolari e i tokenizer.
        3.  Applicare lo stesso preprocessing dell'addestramento al codice di input.
        4.  Eseguire il forward pass del modello (inferenza) per generare la sequenza di indici dei token del riassunto.
        5.  Decodificare la sequenza di indici in una stringa di testo leggibile.
        6.  Stampare a schermo il riassunto generato.


================================================================================

--- FILE: README.md | PATH: Project\src\README.md ---
-----------------------------------------------------

# Cartella `src`

Questa cartella è pensata per contenere il codice sorgente riutilizzabile e le logiche di base che non rientrano specificamente nelle categorie `data`, `models` o `scripts`.

Può essere vista come una libreria interna del progetto.

## Implementazione Prevista

Il contenuto di questa cartella emergerà durante lo sviluppo, ma potrebbe includere:

1.  **Funzioni di Utilità (`utils.py`):**
    *   Funzioni generiche che possono essere utili in più punti del progetto.
    *   Esempi:
        *   Funzioni per calcolare il tempo di esecuzione.
        *   Funzioni per impostare il seed per la riproducibilità degli esperimenti (`set_seed`).
        *   Classi per il logging custom.

2.  **Gestione della Configurazione (`config.py`):**
    *   Un modulo per caricare e gestire i parametri di configurazione del progetto (es. da file YAML o JSON).
    *   Questo centralizza iperparametri come `learning_rate`, `batch_size`, `hidden_size`, percorsi dei file, ecc., rendendo gli esperimenti più facili da tracciare e modificare.

3.  **Logica di Calcolo Metriche (`metrics.py`):**
    *   Wrapper o implementazioni custom per le metriche di valutazione come BLEU e ROUGE, se la logica diventa complessa e si vuole disaccoppiarla dallo script `evaluate.py`.

4.  **Componenti Condivisi del Modello:**
    *   Se si sviluppano architetture più complesse (es. Transformer), qui si potrebbero definire i blocchi base riutilizzabili, come lo strato di `Multi-Head Attention` o `Position-wise Feed-Forward Network`, se non si vogliono tenere nei file principali dei modelli.


================================================================================

